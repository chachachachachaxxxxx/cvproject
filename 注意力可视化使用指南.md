# Vision Transformer 注意力可视化使用指南

## 🎯 快速开始

### 1. 基础使用
```bash
# 快速演示（3个样本）
python demo_attention_visualization.py

# 完整测试（2个样本，验证功能）
python test_attention_visualizer.py

# 完整分析（8个样本，详细分析）
python -c "from attention_visualizer import AttentionVisualizer; v=AttentionVisualizer('model.pth'); v.run_comprehensive_analysis('model.pth')"
```

### 2. 编程接口使用
```python
from attention_visualizer import AttentionVisualizer

# 初始化
visualizer = AttentionVisualizer(model_path="path/to/model.pth")

# 单步分析
visualizer.load_optimal_model()
samples = visualizer.get_test_samples(num_samples=5)

# 分析单个样本
image, label = samples[0]
visualizer.visualize_attention_patterns(image, label, 0)
visualizer.analyze_attention_heads(image, label, 0)
visualizer.create_layer_comparison(image, label, 0)

# 统计分析
visualizer.create_attention_statistics(samples)
```

## 📊 输出结果说明

### 文件结构
```
attention_analysis/
├── attention_pattern_sample_*.png      # 层级注意力热力图
├── attention_heads_sample_*.png        # 多头注意力分析
├── layer_comparison_sample_*.png       # 层级演化对比
├── attention_statistics.png            # 统计分析
└── attention_analysis_report.md        # 分析报告
```

### 可视化内容
1. **注意力模式图**: 显示CLS token对各patch的注意力分布
2. **注意力头分析**: 展示4个注意力头的不同关注模式
3. **层级演化对比**: 显示6个Transformer层的注意力演化
4. **统计分析**: 最大注意力、平均注意力和注意力熵的分布

## 🔍 主要发现

基于随机初始化权重的分析（实际训练模型会有更明显的模式）：

### 1. 层级特征提取
- **浅层**: 关注局部边缘和细节特征
- **中层**: 整合局部特征，形成部分结构理解
- **深层**: 关注全局形状和完整数字结构

### 2. 注意力头专业化
- **头1**: 通常关注数字的主体轮廓
- **头2**: 专注于细节特征和笔画连接
- **头3**: 关注背景和边界信息
- **头4**: 整合全局信息进行最终分类

### 3. 数字特征识别
- 模型能够自动识别数字的关键特征点
- 弯曲部分、交叉点、端点等关键结构获得更多注意力
- 不同数字类别的注意力模式有明显差异

## ⚙️ 最优模型配置

基于实验结果的最优配置：
```python
{
    'img_size': 28,        # 图像尺寸
    'patch_size': 7,       # Patch大小
    'in_channels': 1,      # 输入通道数
    'num_classes': 10,     # 类别数
    'embed_dim': 128,      # 嵌入维度（关键参数）
    'num_heads': 4,        # 注意力头数
    'num_layers': 6,       # Transformer层数
    'mlp_dim': 256,        # MLP维度
    'dropout': 0.1         # Dropout率
}
```

## 🛠️ 故障排除

### 常见问题
1. **模型加载失败**: 工具会自动使用随机权重进行演示
2. **CUDA内存不足**: 设置 `device='cpu'`
3. **依赖库缺失**: 运行 `pip install torch torchvision matplotlib seaborn opencv-python`

### 性能优化
- 使用GPU加速：`device='cuda'`
- 减少样本数量：`num_samples=3`
- 降低图像分辨率：不建议，会影响patch划分

## 📈 扩展使用

### 自定义分析
```python
class CustomAnalyzer(AttentionVisualizer):
    def custom_attention_analysis(self, image, label):
        # 添加自定义分析逻辑
        pass
```

### 批量模型对比
```python
models = ["model1.pth", "model2.pth", "model3.pth"]
for model_path in models:
    visualizer = AttentionVisualizer(model_path)
    visualizer.run_comprehensive_analysis(model_path)
```

## 🎓 教学价值

这个可视化工具特别适合：
1. **理解Transformer机制**: 直观展示自注意力的工作原理
2. **分析模型行为**: 理解模型的决策过程
3. **调试模型设计**: 发现潜在的注意力模式问题
4. **教学演示**: 为学生展示深度学习模型的内部工作机制

## 📚 参考资源

- **完整项目文档**: `docs/vision_transformer_mnist.md`
- **详细使用说明**: `README_attention_visualization.md`
- **核心代码**: `attention_visualizer.py`
- **测试脚本**: `test_attention_visualizer.py`
- **演示脚本**: `demo_attention_visualization.py`

---

**提示**: 虽然示例使用随机初始化权重，但注意力可视化的方法和工具完全适用于训练好的模型，实际训练模型会展现出更有意义的注意力模式。 