#!/usr/bin/env python3
"""
Vision Transformer æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–æ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨æ³¨æ„åŠ›å¯è§†åŒ–å·¥å…·æ¥åˆ†æ
Vision Transformeråœ¨MNISTæ•°æ®é›†ä¸Šçš„æ³¨æ„åŠ›æ¨¡å¼ã€‚

ä½¿ç”¨æ–¹æ³•:
    python demo_attention_visualization.py
"""

import os
import sys
from attention_visualizer import AttentionVisualizer

def main():
    print("ğŸ” Vision Transformer æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–æ¼”ç¤º")
    print("=" * 60)
    
    # æ¨¡å‹è·¯å¾„é…ç½®
    # å¦‚æœæ‚¨æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯·ä¿®æ”¹è¿™ä¸ªè·¯å¾„
    optimal_model_path = "exp/experiments/efficient_ablation_20250609_101146/embed_dim_ablation_embed_dim_128/best_model.pth"
    
    if os.path.exists(optimal_model_path):
        print(f"âœ… æ‰¾åˆ°è®­ç»ƒå¥½çš„æœ€ä¼˜æ¨¡å‹: {optimal_model_path}")
        model_path = optimal_model_path
    else:
        print(f"âš ï¸  æœ€ä¼˜æ¨¡å‹æœªæ‰¾åˆ°: {optimal_model_path}")
        print("ğŸ’¡ å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡è¿›è¡Œæ¼”ç¤º")
        model_path = "demo_model.pth"  # å ä½ç¬¦è·¯å¾„
    
    try:
        # 1. åˆå§‹åŒ–æ³¨æ„åŠ›å¯è§†åŒ–å™¨
        print("\nğŸš€ åˆå§‹åŒ–æ³¨æ„åŠ›å¯è§†åŒ–å™¨...")
        visualizer = AttentionVisualizer(model_path, device='cuda')
        
        # 2. åŠ è½½æ¨¡å‹
        print("\nğŸ“¥ åŠ è½½æœ€ä¼˜ViTæ¨¡å‹é…ç½®...")
        visualizer.load_optimal_model()
        print("   - åµŒå…¥ç»´åº¦: 128")
        print("   - æ³¨æ„åŠ›å¤´æ•°: 4") 
        print("   - Transformerå±‚æ•°: 6")
        print("   - Patchå¤§å°: 7Ã—7")
        
        # 3. è·å–æµ‹è¯•æ ·æœ¬
        print("\nğŸ“Š è·å–MNISTæµ‹è¯•æ ·æœ¬...")
        samples = visualizer.get_test_samples(num_samples=3)  # æ¼”ç¤ºç”¨3ä¸ªæ ·æœ¬
        print(f"   - æˆåŠŸè·å– {len(samples)} ä¸ªä¸åŒç±»åˆ«çš„æ ·æœ¬")
        
        # 4. æ¼”ç¤ºå•ä¸ªæ ·æœ¬çš„è¯¦ç»†åˆ†æ
        print("\nğŸ”¬ æ¼”ç¤ºå•ä¸ªæ ·æœ¬çš„è¯¦ç»†æ³¨æ„åŠ›åˆ†æ...")
        sample_image, sample_label = samples[0]
        
        print(f"   åˆ†ææ ·æœ¬: æ•°å­— {sample_label}")
        
        # åŸºæœ¬æ³¨æ„åŠ›æ¨¡å¼
        print("   - ç”Ÿæˆå±‚çº§æ³¨æ„åŠ›çƒ­åŠ›å›¾...")
        visualizer.visualize_attention_patterns(sample_image, sample_label, 0)
        
        # æ³¨æ„åŠ›å¤´åˆ†æ
        print("   - åˆ†æå¤šå¤´æ³¨æ„åŠ›ä¸“ä¸šåŒ–...")
        visualizer.analyze_attention_heads(sample_image, sample_label, 0)
        
        # å±‚çº§æ¼”åŒ–å¯¹æ¯”
        print("   - åˆ›å»ºå±‚çº§æ³¨æ„åŠ›æ¼”åŒ–å¯¹æ¯”...")
        visualizer.create_layer_comparison(sample_image, sample_label, 0)
        
        # 5. æ‰¹é‡å¤„ç†æ‰€æœ‰æ ·æœ¬
        print(f"\nâš¡ æ‰¹é‡å¤„ç†æ‰€æœ‰ {len(samples)} ä¸ªæ ·æœ¬...")
        for i, (image, label) in enumerate(samples[1:], 1):  # è·³è¿‡å·²å¤„ç†çš„ç¬¬ä¸€ä¸ª
            print(f"   å¤„ç†æ ·æœ¬ {i+1}: æ•°å­— {label}")
            visualizer.visualize_attention_patterns(image, label, i)
            visualizer.analyze_attention_heads(image, label, i)
            visualizer.create_layer_comparison(image, label, i)
        
        # 6. ç»Ÿè®¡åˆ†æ
        print("\nğŸ“ˆ ç”Ÿæˆç»Ÿè®¡åˆ†æ...")
        visualizer.create_attention_statistics(samples)
        
        # 7. ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        visualizer._generate_analysis_report(samples)
        
        # 8. æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {visualizer.output_dir}")
        print("\nğŸ“‚ ç”Ÿæˆçš„æ–‡ä»¶:")
        
        if os.path.exists(visualizer.output_dir):
            files = sorted(os.listdir(visualizer.output_dir))
            for file in files:
                file_path = os.path.join(visualizer.output_dir, file)
                if os.path.isfile(file_path):
                    file_size = os.path.getsize(file_path)
                    file_type = get_file_description(file)
                    print(f"   ğŸ“„ {file:<35} ({file_size:>8,} bytes) - {file_type}")
        
        print("\nğŸ” ä¸»è¦å¯è§†åŒ–å†…å®¹:")
        print("   ğŸ“Š attention_pattern_sample_*.png  - æ¯å±‚æ³¨æ„åŠ›çƒ­åŠ›å›¾å¯¹æ¯”")
        print("   ğŸ¯ attention_heads_sample_*.png    - å¤šå¤´æ³¨æ„åŠ›ä¸“ä¸šåŒ–åˆ†æ") 
        print("   ğŸ“ˆ layer_comparison_sample_*.png   - å±‚çº§æ³¨æ„åŠ›æ¼”åŒ–è¿‡ç¨‹")
        print("   ğŸ“‰ attention_statistics.png       - æ³¨æ„åŠ›ç»Ÿè®¡ç‰¹å¾åˆ†æ")
        print("   ğŸ“‹ attention_analysis_report.md   - è¯¦ç»†åˆ†ææŠ¥å‘Š")
        
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("   1. æŸ¥çœ‹ attention_pattern_sample_*.png äº†è§£æ¨¡å‹å…³æ³¨çš„å›¾åƒåŒºåŸŸ")
        print("   2. åˆ†æ attention_heads_sample_*.png ç†è§£å¤šå¤´æ³¨æ„åŠ›çš„åˆ†å·¥")
        print("   3. è§‚å¯Ÿ layer_comparison_sample_*.png ç†è§£ç‰¹å¾æå–çš„å±‚çº§æ€§")
        print("   4. é˜…è¯» attention_analysis_report.md è·å–è¯¦ç»†åˆ†æç»“è®º")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def get_file_description(filename):
    """è·å–æ–‡ä»¶ç±»å‹æè¿°"""
    if filename.startswith('attention_pattern_'):
        return "æ³¨æ„åŠ›æ¨¡å¼çƒ­åŠ›å›¾"
    elif filename.startswith('attention_heads_'):
        return "å¤šå¤´æ³¨æ„åŠ›åˆ†æ"
    elif filename.startswith('layer_comparison_'):
        return "å±‚çº§æ³¨æ„åŠ›å¯¹æ¯”"
    elif filename == 'attention_statistics.png':
        return "æ³¨æ„åŠ›ç»Ÿè®¡åˆ†æ"
    elif filename == 'attention_analysis_report.md':
        return "è¯¦ç»†åˆ†ææŠ¥å‘Š"
    else:
        return "å…¶ä»–æ–‡ä»¶"

if __name__ == "__main__":
    print("Vision Transformer æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–æ¼”ç¤º")
    print("åŸºäºMNISTæ‰‹å†™æ•°å­—è¯†åˆ«ä»»åŠ¡")
    print("-" * 60)
    
    success = main()
    
    if success:
        print("\nâœ… æ¼”ç¤ºæˆåŠŸå®Œæˆï¼")
        print("\nğŸ”— ç›¸å…³èµ„æº:")
        print("   - å®Œæ•´é¡¹ç›®æ–‡æ¡£: docs/vision_transformer_mnist.md")
        print("   - ä½¿ç”¨è¯´æ˜: README_attention_visualization.md")
        print("   - æµ‹è¯•è„šæœ¬: test_attention_visualizer.py")
    else:
        print("\nâŒ æ¼”ç¤ºæœªèƒ½å®Œæˆï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        sys.exit(1) 